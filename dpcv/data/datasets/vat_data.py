import torch
from torch.utils.data import DataLoader
from dpcv.data.transforms.transform import set_vat_transform_op
from dpcv.data.datasets.video_segment_data import VideoFrameSegmentData
from dpcv.data.datasets.tpn_data import TPNData as VATData
from dpcv.data.datasets.tpn_data import TPNTruePerData as VATTruePerData
from dpcv.data.datasets.tpn_data import FullTestTPNData as FullTestVATData
from dpcv.data.transforms.temporal_transforms import TemporalRandomCrop, TemporalDownsample, TemporalEvenCropDownsample
from dpcv.data.transforms.temporal_transforms import Compose as TemporalCompose
from dpcv.data.datasets.build import DATA_LOADER_REGISTRY
from dpcv.data.transforms.build import build_transform_spatial, build_transform_temporal
from dpcv.data.datasets.common import VideoLoader


def make_data_loader(cfg, mode="train"):

    assert (mode in ["train", "valid", "trainval", "test"]), "'mode' should be 'train' , 'valid' or 'trainval'"
    spatial_transform = set_vat_transform_op()
    temporal_transform = [TemporalRandomCrop(16)]
    temporal_transform = TemporalCompose(temporal_transform)
    video_loader = VideoLoader()

    if mode == "train":
        data_set = VATData(
            cfg.DATA_ROOT,
            cfg.TRAIN_IMG_DATA,
            cfg.TRAIN_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
        )
    elif mode == "valid":
        data_set = VATData(
            cfg.DATA_ROOT,
            cfg.VALID_IMG_DATA,
            cfg.VALID_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
        )
    elif mode == "trainval":
        data_set = VATData(
            cfg.DATA_ROOT,
            cfg.TRAINVAL_IMG_DATA,
            cfg.TRAINVAL_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
        )
    else:
        data_set = VATData(
            cfg.DATA_ROOT,
            cfg.TEST_IMG_DATA,
            cfg.TEST_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
        )
    data_loader = DataLoader(
        dataset=data_set,
        batch_size=cfg.TRAIN_BATCH_SIZE,
        shuffle=cfg.SHUFFLE,
        num_workers=cfg.NUM_WORKERS,
    )
    return data_loader


@DATA_LOADER_REGISTRY.register()
def vat_data_loader(cfg, mode="train"):

    assert (mode in ["train", "valid", "trainval", "test", "full_test"]), \
        "'mode' should be 'train' , 'valid' or 'trainval'"
    spatial_transform = build_transform_spatial(cfg)
    temporal_transform =  build_transform_temporal(cfg)   # temporal_transform = [TemporalDownsample(length=16)]

    data_cfg = cfg.DATA
    if "face" in data_cfg.TRAIN_IMG_DATA:
        video_loader = VideoLoader(image_name_formatter=lambda x: f"face_{x}.jpg")
    else:
        video_loader = VideoLoader(image_name_formatter=lambda x: f"frame_{x}.jpg")

    if mode == "train":
        data_set = VATData(
            data_cfg.ROOT,
            data_cfg.TRAIN_IMG_DATA,
            data_cfg.TRAIN_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
            data_cfg.TRAIN_NUM_VIDEOS,
            traits=data_cfg.TRAITS,
            specify_videos=data_cfg.TRAIN_SPECIFY_VIDEOS,
        )
    elif mode == "valid":
        data_set = VATData(
            data_cfg.ROOT,
            data_cfg.VALID_IMG_DATA,
            data_cfg.VALID_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
            data_cfg.VALID_NUM_VIDEOS,
            traits=data_cfg.TRAITS,
            specify_videos=data_cfg.VALID_SPECIFY_VIDEOS,
        )
    elif mode == "trainval":
        data_set = VATData(
            data_cfg.ROOT,
            data_cfg.TRAINVAL_IMG_DATA,
            data_cfg.TRAINVAL_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
            traits=data_cfg.TRAITS,
        )
    elif mode == "full_test":
        temporal_transform = [TemporalDownsample(length=100), TemporalEvenCropDownsample(16, 6)]
        temporal_transform = TemporalCompose(temporal_transform)
        return FullTestVATData(
            data_cfg.ROOT,
            data_cfg.TEST_IMG_DATA,
            data_cfg.TEST_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
            traits=data_cfg.TRAITS,
            specify_videos=data_cfg.TEST_SPECIFY_VIDEOS,
        )
    else:
        data_set = VATData(
            data_cfg.ROOT,
            data_cfg.TEST_IMG_DATA,
            data_cfg.TEST_LABEL_DATA,
            video_loader,
            spatial_transform,
            temporal_transform,
            data_cfg.TEST_NUM_VIDEOS,
            traits=data_cfg.TRAITS,
            specify_videos=data_cfg.TEST_SPECIFY_VIDEOS,
        )

    loader_cfg = cfg.DATA_LOADER
    data_loader = DataLoader(
        dataset=data_set,
        batch_size=loader_cfg.TRAIN_BATCH_SIZE,
        shuffle=loader_cfg.SHUFFLE,
        num_workers=loader_cfg.NUM_WORKERS,
    )
    return data_loader


@DATA_LOADER_REGISTRY.register()
def true_per_vat_data_loader(cfg, mode="train"):
    assert (mode in ["train", "valid", "trainval", "test", "full_test"]), \
        "'mode' should be 'train' , 'valid' or 'trainval'"
    spatial_transform = build_transform_spatial(cfg)
    temporal_transform = [TemporalRandomCrop(16)]
    # temporal_transform = [TemporalDownsample(length=2000), TemporalRandomCrop(16)]
    temporal_transform = TemporalCompose(temporal_transform)

    data_cfg = cfg.DATA
    if data_cfg.TYPE == "face":
        video_loader = VideoLoader(image_name_formatter=lambda x: f"face_{x}.jpg")
    else:
        video_loader = VideoLoader(image_name_formatter=lambda x: f"frame_{x}.jpg")

    data_set = VATTruePerData(
        data_root="datasets/chalearn2021",
        data_split=mode,
        task=data_cfg.SESSION,
        data_type=data_cfg.TYPE,
        video_loader=video_loader,
        spa_trans=spatial_transform,
        tem_trans=temporal_transform,
        visual_clip=data_cfg.VISUAL_CLIP
    )

    shuffle = True if mode == "train" else False
    loader_cfg = cfg.DATA_LOADER
    data_loader = DataLoader(
        dataset=data_set,
        batch_size=loader_cfg.TRAIN_BATCH_SIZE,
        shuffle=shuffle,
        num_workers=loader_cfg.NUM_WORKERS,
    )
    return data_loader


@DATA_LOADER_REGISTRY.register()
def all_true_per_vat_data_loader(cfg, mode="train"):
    from torch.utils.data.dataset import ConcatDataset
    assert (mode in ["train", "valid", "trainval", "test", "full_test"]), \
        "'mode' should be 'train' , 'valid' or 'trainval'"
    spatial_transform = build_transform_spatial(cfg)
    temporal_transform = [TemporalRandomCrop(16)]
    # temporal_transform = [TemporalDownsample(length=2000), TemporalRandomCrop(16)]
    temporal_transform = TemporalCompose(temporal_transform)

    data_cfg = cfg.DATA
    if data_cfg.TYPE == "face":
        video_loader = VideoLoader(image_name_formatter=lambda x: f"face_{x}.jpg")
    else:
        video_loader = VideoLoader(image_name_formatter=lambda x: f"frame_{x}.jpg")


    datasets = []
    # for session in ["ghost"]:
    for session in ["ghost", "animal", "talk", "lego"]:
        data_set = VATTruePerData(
            data_root=data_cfg.ROOT,  # "datasets/chalearn2021",
            data_split=mode,
            task=session,
            data_type=data_cfg.TYPE,
            video_loader=video_loader,
            spa_trans=spatial_transform,
            tem_trans=temporal_transform,
            traits=data_cfg.TRAITS
        )
        datasets.append(data_set)
    concat_dataset = ConcatDataset(datasets)

    shuffle = True if mode == "train" else False
    loader_cfg = cfg.DATA_LOADER
    data_loader = DataLoader(
        dataset=concat_dataset,
        batch_size=loader_cfg.TRAIN_BATCH_SIZE,
        shuffle=shuffle,
        num_workers=loader_cfg.NUM_WORKERS,
    )
    return data_loader


if __name__ == "__main__":
    import os
    from dpcv.config.tpn_cfg import cfg

    os.chdir("../../")

    # interpret_data = InterpretData(
    #     data_root="datasets",
    #     img_dir="image_data/valid_data",
    #     label_file="annotation/annotation_validation.pkl",
    #     trans=set_transform_op(),
    # )
    # print(interpret_data[18])

    data_loader = make_data_loader(cfg, mode="valid")
    for i, item in enumerate(data_loader):
        print(item["image"].shape, item["label"].shape)
        if i > 5:
            break
